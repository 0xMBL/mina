# Notes on super catchup run logic

### Quick definitions

- Block recap: a block contains a hash of the current ledger, and a `staged_ledger_diff`, which is effectively a list of transactions that change the previous staged ledger to the current block's staged ledger. A transaction is of the form "acct a sends X mina tokens to acct B". It doesn't tell you the balances of acct A and B. The block does not contain the ledger in it's entirety, nor can any account balances be looked up.  https://docs.minaprotocol.com/en/architecture/whats-in-a-block#staged-ledger-diff

- Breadcrumb: a breadcrumb is a block which has been fully validated and given an attached and connected ledger mask which connects to the previous mask which eventually connects to a ledger, and so an attached mask in essence is a full ledger. breadcrumbs are the "nodes" in a transition frontier. breadcrumbs can only exist if the parent breadcrumb already exists in the transition frontier, because the parent is necessary for validating and of course a fully attached ledger mask can only exist if there exists a previous ledger.  the transition frontier, being made of breadcrumbs, is therefore always fully connected.

- Transition frontier: the transition frontier is a tree of breadcrumbs with max height of `k`, where `k` is a constant defined by the crypto team, currently set at `k = 209`.  the transition frontier is the very most recent `k` number of blocks, as well as all the forks, or sidechains, off of the current longest chain.  the block-chain path through the transition frontier with the best chain quality metric is considered the current canonical chain, and the tip of this canonical chain is called the best-tip.  

- Bootstrap, high level: bootstrap is the process of using zk-snarks to validate the validity of the chain, from the last known block (which would be the genesis block for fresh daemons just starting up) to the best tip.

- Catchup, high level: catchup is invoked whenever there is a "gap" in the transition frontier, or more specifically when a new block cannot be connected and added to the transition frontier. bootstrap, when it finishes, should yield us a fully connected transition frontier from the frontier root to the best tip. however there will always be sidechains such that bootstrap almost inevitably creates a number of catchup jobs.  in such a case, the tips of the sidechains are passed to catchup, and catchup needs to fill in the gaps and connect it to a known breadcrumb in the transition frontier.  catchup jobs are also created whenever the network for whatever reason doesn't deliver to a daemon recent blocks in time, creating a gap in the transition frontier, and as such catchup will be invoked.

- catchup scheduler: the scheduler is not a part of catchup, however it controls the logic of when catchup should be invoked. when a block that has no parent is received, it gets passed to the scheduler, which then usually waits some time to see if the parent gets gossiped, and if it hasn't been, then the scheduler invokes a catchup job. 

- normal and super catchup: There's two kinds of catchup in the code, normal and super catchup.  They both do the same thing, normal catchup is simply the older deprecated version.  At this moment, by default super catchup is used.  there is a mina flag `--no-super-catchup` which instructs the daemon to use the older normal-catchup, though few people do that.  the already deprecated “normal” catchup will be removed at some point and then “super” catchup will become the only catchup.  everything in this doc describes super catchup, which at this point is more normal than normal catchup.

### Catchup specifics

- super catchup uses a data structure called `full_catchup_tree`. each node of this tree basically represents a block that needs to be downloaded, verified, validated, and turned into a breadcrumb and added to the transition frontier (arguably it would be better to name them "jobs" instead of "nodes"). each job goes through those phases.
    - the catchup tree is a trees of hashes of blocks, which are in a pending state and need to be downloaded and processed into the transition frontier. (it's actually a forest and not one tree, but this is just because the scheduler passes to catchup a bunch of blocks in a tree minus their common root, so it becomes a forest)
- within the `run` function of super catchup, first it sets up a number of dependencies and creates a few aux functions.
    - there is a very important interior function defined within the super_catchup run function called `run_node`. `run_node` is a state machine which puts each node (ie a job) of the catchup tree through it's phases. it takes a node of the transition frontier, and either fully downloads it, validates it, builds it into a breadcrumb, or builds the parent into a breadcrumb. the function looks like a big match-case expression that handles all the stages of a node. it recursively calls itself to handle the subsequent stages.
    - the downloader is also created in the beginning of the `run` function. has a list of blocks that need to be downloaded. super catchup (i believe) downloads in a more forward order towards the target.
- the main operative line in super catchup starts with `Strict_pipe.Reader.iter_without_pushback catchup_job_reader ~f:(fun (target_parent_hash, forest) -> <......> )`. the huge anonymous function defined in `~f` has all the real business logic in catchup.  This line uses Strict_pipe to define the reader end of a pipe.
    - the scheduler has the writer end of this pipe. the scheduler will bundle up node/jobs(/ie connected blocks that don't connected further) into a forest structure and pass it into the pipe. the reader reads from this pipe and gets a `forest` of catchup jobs, and a `target_parent_hash`. the `target_parent_hash` input argument is relevant for the downloader.  `target_parent_hash` is the parent of the oldest missing block we have received through gossip (though this oldest missing block is not necessarily all that we need).  the forest contains the blocks that were received but have `target_parent_hash` as their parent, so on other words if `target_parent_hash` was added to the forest, then the forest would become a simple tree with `target_parent_hash` as the root.
    - the first `don't_wait_for` interacts with a pipe that connects to the downloader. it updates some context info for the downloader
    - the second `don't_wait_for` is by far the bulk of the work in super catchup.
        - first, the `state_hashes` var is obtained.  A part of this involves checking using the function `try_to_connect_hash_chain` to see if `target_parent_hash` is the oldest block the daemon is missing— ie that the parent of `target_parent_hash` is already in the daemon's transition frontier.  If so, then we're good to go; but if not, then that means there are further missing blocks, and the downloader is called with function `download_state_hashes`, which makes sure to contact peers over the network in order to download the whole chain of block hashes going back to a block who's parent is in the daemon's existing transition frontier.
        - what `state_hashes` actually is, is a tuple where the first member is the root (of the forest/tree segment i think), and the second member is a list of block hashes of the blocks in the forest (i think). a result type takes 2 arguments. the first is the Ok type, the second is the Error type.  the Ok type is a tuple of (the node or breadcrumb, a list of hashes).  the error type is a list of ad-hoc error codes.  state_hashes is of type:
        
        ```ocaml
        ([> Breadcrumb of Breadcrumb.t | Node of Node.t ] * (Marlin_plonk_bindings_pasta_fp.t list),
         [> Failed_to_download_transition_chain_proof | Invalid_transition_chain_proof | No_common_ancestor | Peer_moves_too_fast ] list
        ) result
        ```
        
        - the next thing that happens is that we iterate through the forest and call `run_node` on everything. this doesn't depend on `state_hashes`. this is where most of the work is done, because `run_node` invokes the state machine, and this state machine through recursion and blocking will automatically attempt to build jobs into breadcrumbs and add to transition frontier.  as such it doesn't really matter what order jobs get called with `run_node` on.